{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Natural Language Processing: coursework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microsoft Research Sentence Completion Challenge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate number: 250939"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Microsoft Research Sentence Completion Challenge requires a system to be able to predict which is the most likely word (from a set of 5 possibilities) to complete a sentence. In this assignment you are expected to\n",
    "investigate at least 2 extensions or alternative approaches to making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IN this assignmnet I am investigating CBOW and Trigram models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file shows the implementation of CBOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the necessary libraries for the code\n",
    "import nltk\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "from nltk import word_tokenize as tokenize\n",
    "import operator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "import shutil\n",
    "import tempfile\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.utilities.cloud_io import load as pl_load\n",
    "import re\n",
    "from gutenberg.acquire import load_etext\n",
    "from gutenberg.cleanup import strip_headers\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "import pandas as pd, csv\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrscc_dir = '/Users/sumitbajare/Documents/Sussex/Sem2/ANLP/lab2resources/sentence-completion' # parent directory\n",
    "def get_train_val(training_dir=mrscc_dir,split=0.5):\n",
    "    \n",
    "    '''\n",
    "        Getting the names of files in the training directory and \n",
    "        split them into training and testing 50:50.\n",
    "    :param: training_dir,split\n",
    "    :return: filenames[:index],filenames[index:]\n",
    "    '''\n",
    "    \n",
    "    filenames=os.listdir(training_dir)\n",
    "    n=len(filenames)\n",
    "    print(f\"There are {n} files in the training directory: {training_dir}\")\n",
    "    random.seed(7) #if you want the same random split every time\n",
    "    random.shuffle(filenames)\n",
    "    index=int(n*split)\n",
    "    return(filenames[:index],filenames[index:])\n",
    "\n",
    "trainingdir=os.path.join(mrscc_dir,'Holmes_Training_Data/')\n",
    "training,testing=get_train_val(trainingdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processfiles(files, training_dir, filter=\"Conan Doyle\"):\n",
    "    \n",
    "    '''\n",
    "        Processing the file \n",
    "    :param: files, training_dir, filter\n",
    "    :return: texts\n",
    "    '''\n",
    "    \n",
    "    texts = []\n",
    "    for i, j in enumerate(files):\n",
    "        text = \"\"\n",
    "        try:\n",
    "            with open(os.path.join(training_dir,j)) as instream:\n",
    "                for line in instream:\n",
    "                    text += line\n",
    "                if re.search(filter, text, re.IGNORECASE) or i%15==0:\n",
    "                    #returns a match object when the pattern is found and “null” if the pattern is not found\n",
    "                    print(\"sherlock found at {}\".format(i))\n",
    "                    texts.append(strip_headers(text).strip())              \n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"UnicodeDecodeError processing {j}: ignoring rest of file\")\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = processfiles(training, trainingdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the Questions \n",
    "questions=pd.read_csv(os.path.join(mrscc_dir,\"testing_data.csv\")) #reading the questions csv file\n",
    "answers=pd.read_csv(os.path.join(mrscc_dir,\"test_answer.csv\"))# reading the answers csv file\n",
    "choices = ['a','b','c','d','e'] # 5 choices\n",
    "questions.rename(columns={'a)':'a','b)':'b','c)':'c','d)':'d','e)':'e'}, inplace=True) # renaming the columns for more clear understanding\n",
    "word_answers, question_with_answer, question_with_mask = [], [], [] # creating a list for all three\n",
    "for index,row in questions.iterrows():\n",
    "    answer = answers.iloc[index].answer\n",
    "    word_answers.append(row[answer])\n",
    "    question_with_answer.append(re.sub(\"_____\",row[answer],row.question))\n",
    "questions['answer'] = word_answers\n",
    "questions['question_with_answer'] = question_with_answer\n",
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processfiles(all_texts, questions=questions, config={\"stop\":True, \"window_size\":4}):\n",
    "    \n",
    "    '''\n",
    "        Generating a pairs of context and targets, \n",
    "        For every target word n; n-2,n-1,n+1,n+2 context words will be generated\n",
    "        creating a rolling window over the text\n",
    "    :param: all_texts, questions=questions, config\n",
    "    :return: train, vocab\n",
    "    '''\n",
    "    \n",
    "    window = config['window_size']\n",
    "    vocab = set()\n",
    "    contexts,targets=[],[]\n",
    "    stop = set(stopwords.words('english') + list(string.punctuation))\n",
    "    for text in all_texts:\n",
    "        if config['stop']:\n",
    "            tokenized_text = [i for i in word_tokenize(text.lower()) if i not in stop]\n",
    "        else:\n",
    "            tokenized_text = [i for i in word_tokenize(text.lower())]\n",
    "        vocab.update(tokenized_text)\n",
    "        for i in range(window, len(tokenized_text) - window - 1):\n",
    "            contexts.append(tokenized_text[i-window:i] + tokenized_text[i+1:i+window+1])\n",
    "            targets.append(tokenized_text[i])\n",
    "    train = pd.DataFrame()\n",
    "    train['contexts']=contexts\n",
    "    train['targets']=targets\n",
    "    for i,row in questions.iterrows():\n",
    "        stop = set(stopwords.words('english') + list(string.punctuation))\n",
    "        if config['stop']==True:\n",
    "            question_tokens = [i for i in word_tokenize(row.question.lower()) if i not in stop]\n",
    "        else:\n",
    "            question_tokens = [i for i in word_tokenize(row.question.lower())]\n",
    "        vocab.update(question_tokens)\n",
    "        vocab.update(list(row[choices]))\n",
    "    return train, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, vocab = processfiles(texts,config={\"stop\":True, \"window_size\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[100].contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYthon Lightening DAtatset\n",
    "class PLDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame, vocab: dict):\n",
    "        \n",
    "        '''\n",
    "            This is the constructor method\n",
    "        :param: data, vocab\n",
    "        '''\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        '''\n",
    "            This is a built-in functions that gets the number of items in the container self.data \n",
    "        :return data\n",
    "        '''\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        '''\n",
    "           This is a built-in functions; Used for accessing list items, dictionary entries, array elements etc. \n",
    "        :param: data, vocab\n",
    "        :return: context_ids, target_id, dtype\n",
    "        '''\n",
    "        row = self.data.iloc[index]\n",
    "        context = row.contexts\n",
    "        target = row.targets\n",
    "        return {'context_ids':torch.tensor([self.vocab[w] for w in context], dtype=torch.long),'target_id':torch.tensor(self.vocab[target], dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "test = PLDataset(train.head(), word_to_ix)\n",
    "test.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Python Lightening DAtaset\n",
    "class PLTestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame, vocab: dict, window: int=4):\n",
    "        \n",
    "        '''\n",
    "            This is the constructor method\n",
    "        :param: data, vocab, window\n",
    "        '''\n",
    "    \n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.window = window\n",
    "        self.stop = set(stopwords.words('english') + list(string.punctuation))\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        '''\n",
    "            This is a built-in functions that gets the number of items in the container self.data \n",
    "        :return data\n",
    "        '''\n",
    "        \n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int, target=\"_____\"):\n",
    "        \n",
    "        '''\n",
    "            This is a built-in functions; Used for accessing list items, dictionary entries, array elements etc.\n",
    "        :param: index, target\n",
    "        :return: context_ids, dtype, target_id\n",
    "        '''\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        question = row.question\n",
    "        answer = row.answer.lower()\n",
    "        question_tokens = [i for i in word_tokenize(question.lower()) if i not in self.stop]\n",
    "        window_left,window_right = self.window,self.window\n",
    "        for i,word in enumerate(question_tokens):\n",
    "            if word == target:\n",
    "                if i<window_left:\n",
    "                    window_right = window_right+(window_left-1)\n",
    "                if i>(len(question_tokens)-window_right):\n",
    "                    window_left = window_left+(len(question_tokens)-i)\n",
    "                context = question_tokens[i-window_left+1:i]+question_tokens[i+1:i+1+window_right]\n",
    "                break\n",
    "        return {'context_ids':torch.tensor([self.vocab[w] for w in context], dtype=torch.long),'target_id':torch.tensor(self.vocab[answer], dtype=torch.long)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = PLTestDataset(questions.head(), word_to_ix)\n",
    "test.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python Lightning DAtaModule\n",
    "#A DataModule is simply a collection of a train_dataloader(s), val_dataloader(s), test_dataloader(s) and predict_dataloader(s) \n",
    "#along with the matching transforms and data processing/downloads steps required.\n",
    "\n",
    "class PLDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_data, test_data, batch_size=16, vocab=word_to_ix, window=4):\n",
    "        \n",
    "        '''\n",
    "            This is the constructor method\n",
    "        :param: train_data, test_data, batch_size, vocab, window\n",
    "        '''\n",
    "    \n",
    "        super().__init__()\n",
    "        print(len(train_data))\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.batch_size = batch_size\n",
    "        self.vocab = vocab\n",
    "        self.window = window\n",
    "\n",
    "    def setup(self):\n",
    "        \n",
    "        \"\"\"\n",
    "            Assign train & test datasets for use in dataloaders\n",
    "        \"\"\"\n",
    "        \n",
    "        self.train_dataset = PLDataset\n",
    "        self.train_data\n",
    "        self.vocab\n",
    "        self.test_dataset = PLTestDataset\n",
    "        self.test_data\n",
    "        self.vocab\n",
    "        self.window\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \n",
    "        '''\n",
    "            Generating the training dataloaders\n",
    "        :return DataLoader\n",
    "        '''\n",
    "        \n",
    "        return DataLoader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        \n",
    "        '''\n",
    "            Generate the validation dataloaders\n",
    "        :return: Dataloader(self.test_dataset,batch_size=1,num_workers=2)\n",
    "        '''\n",
    "        \n",
    "        return DataLoader(self.test_dataset,batch_size=1,num_workers=2)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        \n",
    "        '''\n",
    "             Generate the test dataloaders\n",
    "        :return: DataLoader(self.test_dataset,batch_size=1,num_workers=2)\n",
    "        '''\n",
    "        \n",
    "        return DataLoader(self.test_dataset,batch_size=1,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the CBOW model\n",
    "class CBOWModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, config, vocab):\n",
    "        \n",
    "        '''\n",
    "            This is the constructor method\n",
    "        :param: config, vocab\n",
    "        '''\n",
    "    \n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.vocab = vocab\n",
    "        self.embeddings = nn.Embedding(num_embeddings=config['vocab_size'],embedding_dim=config['embedding_dim'])\n",
    "        self.linear = nn.Linear(in_features=config['embedding_dim'],out_features=config['vocab_size'])\n",
    "        torch.nn.init.xavier_normal_(self.linear.weight)\n",
    "        self.accuracy = pl.metrics.Accuracy()\n",
    "        self.loss_function = nn.NLLLoss()\n",
    "\n",
    "    def forward(self, inputs, target=None):\n",
    "        embeds = torch.mean(self.embeddings(inputs), dim=1)\n",
    "        logits = self.linear(embeds)\n",
    "        out = F.log_softmax(logits, dim=1)\n",
    "        loss = 0\n",
    "        if target is not None:  \n",
    "            loss = self.loss_function(out, target)\n",
    "        return loss, logits\n",
    "\n",
    "    def training_step(self, batch, batch_index):\n",
    "        \n",
    "        '''\n",
    "            Training the model\n",
    "        :param: batch, batch_index\n",
    "        : return: loss\n",
    "        '''\n",
    "        \n",
    "        context_ids = batch['context_ids']\n",
    "        target_id = batch['target_id']\n",
    "        loss, outputs = self(context_ids, target_id)\n",
    "        self.log(\"train loss\", loss, prog_bar = True, logger=True)\n",
    "        return {\"loss\":loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_index):\n",
    "        \n",
    "        '''\n",
    "            Validating the model\n",
    "        :param:batch, batch_index\n",
    "        :return: val_loss, val_outputs\n",
    "        '''\n",
    "        \n",
    "        context_ids = batch['context_ids']\n",
    "        target_id = batch['target_id']\n",
    "        loss, outputs = self(context_ids, target_id)\n",
    "        self.log(\"validation loss \", loss, prog_bar = True, logger=True)\n",
    "        return {\"val_loss\": loss, \"val_outputs\": outputs}\n",
    "                \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \n",
    "        '''\n",
    "            validation loss and accuracy\n",
    "        :param: outputs\n",
    "        '''\n",
    "        \n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        all_outputs = [x[\"val_outputs\"] for x in outputs]\n",
    "        preds=[]\n",
    "        for output in all_outputs:\n",
    "            for i,row in questions.iterrows():\n",
    "                choice_ids = [self.vocab[row[c]] for c in choices]\n",
    "                choice_logits = [float(output[0, id]) for id in choice_ids]\n",
    "                preds.append(np.argmax(np.array(choice_logits)))\n",
    "        total,correct=0,0\n",
    "        for answer,pred in zip(answers.answer, preds):\n",
    "            total+=1\n",
    "            if answer==choices[pred]:\n",
    "                correct+=1\n",
    "        print(f\"test accuracy {correct/total}\")\n",
    "        self.log(\"ptl/val_loss\", avg_loss)\n",
    "        self.log(\"ptl/val_accuracy\", correct/total)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        '''\n",
    "            Initializing the optimizer\n",
    "        :return: optimizer\n",
    "        '''\n",
    "        \n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.config['lr'])\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the model\n",
    "config = {\"lr\": 2e-5,\"batch_size\": 128,\"embedding_dim\":256,\"vocab_size\":len(vocab),\"n_epochs\":6,\"stop\":False}\n",
    "print(\"Training set size: {}\".format(len(train)))\n",
    "print(\"Vocab set size: {}\".format(len(vocab)))\n",
    "model = CBOWModel(config, vocab=word_to_ix)\n",
    "data_module = PLDataModule(train, questions, batch_size=config['batch_size'],vocab=word_to_ix)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TuneReportCallback({\"accuracy\": \"ptl/val_accuracy\",\"loss\": \"ptl/val_loss\"}, on=\"validation_end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tune(config, gpus=0):\n",
    "    '''\n",
    "        Hyperparamter tuning with ray\n",
    "    :param: config, gpus\n",
    "    '''\n",
    "    train, vocab = processfiles(texts, config=config)\n",
    "    word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "    print(\"Training set size: {}\".format(len(train)))\n",
    "    model = CBOWModel(config,vocab=word_to_ix)\n",
    "    data_module = PLDataModule(train, questions, vocab=word_to_ix, batch_size=config['batch_size'])\n",
    "    print(\"Steps per epoch {}\".format(len(train)/config['batch_size']))\n",
    "    data_module.setup()\n",
    "    trainer = pl.Trainer(max_epochs=5,gpus=config[\"n_gpus\"],progress_bar_refresh_rate=1000,logger=TensorBoardLogger(save_dir=tune.get_trial_dir(), name=\" \", version=\".\"),callbacks=[callback])\n",
    "    trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_cbow(config, num_samples=3, gpus_per_trial=0):\n",
    "    '''\n",
    "        Hyperparameter tuning CBOW wit ray\n",
    "    :param:config, num_samples, gpus_per_trial\n",
    "    '''\n",
    "    scheduler = ASHAScheduler(metric='accuracy',mode='max',grace_period=3,reduction_factor=2)\n",
    "    reporter = CLIReporter(parameter_columns=[\"lr\", \"batch_size\", \"embedding_dim\", 'stop', \"window_size\"],metric_columns=[\"loss\",\"accuracy\", \"training_iteration\"])\n",
    "    trainable = tune.with_parameters(train_tune,gpus=config[\"n_gpus\"])\n",
    "    analysis = tune.run(trainable,resources_per_trial={\"cpu\": 1, \"gpu\": config[\"n_gpus\"]},config=config,scheduler=scheduler,progress_reporter=reporter,num_samples=num_samples,name=\"tune_cbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters \n",
    "config = {\"lr\": tune.choice([2e-6,2e-5,2e-4]), \"batch_size\": 64,\"embedding_dim\":tune.choice([64,128,256]),\"vocab_size\":len(vocab), \"n_epochs\":20,\"stop\":tune.choice([True, False]),\"window_size\":tune.choice([2,3,4,5,10]),\"n_gpus\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis = tune_cbow(config, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([ word_to_ix['went'], word_to_ix['city'], word_to_ix['walking'], word_to_ix['streets'], word_to_ix['capital'], word_to_ix['building']])\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, log_probs = model(torch.unsqueeze(test, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.argmax(log_probs)\n",
    "ix_to_word = dict((v,k) for k,v in word_to_ix.items())\n",
    "ix_to_word[int(torch.argmax(log_probs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the data \n",
    "class question:\n",
    "    def __init__(self, aline, lm):\n",
    "        \n",
    "        '''\n",
    "            This is the constructor method\n",
    "        :param: aline, lm\n",
    "        '''\n",
    "        \n",
    "        self.sentence=aline[1]\n",
    "        self.choices = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
    "        self.word_choices = {index:word for index,word in zip(self.choices,aline[2:])}\n",
    "        self.model = model\n",
    "\n",
    "    def add_answer(self,fields):\n",
    "        \n",
    "        '''\n",
    "            Adding answer field\n",
    "        :param: fileds\n",
    "        '''\n",
    "        \n",
    "        self.answer=fields[1]\n",
    "\n",
    "    def get_window_context(self,sent_tokens,window_left, window_right,target=\"_____\"):\n",
    "        \n",
    "        '''\n",
    "           getting window context; changing the right and left window \n",
    "        :param: sent_tokens,window_left, window_right,target\n",
    "        return: tokens\n",
    "        '''\n",
    "        \n",
    "        stop = set(stopwords.words('english') + list(string.punctuation))\n",
    "        tokens = [i for i in word_tokenize(sent_tokens.lower()) if i not in stop]\n",
    "        for i,token in enumerate(tokens):\n",
    "            if token==target:\n",
    "                if i<window_left:\n",
    "                    window_right = window_right+(window_left-1)\n",
    "                if i>(len(tokens)-window_right):\n",
    "                    window_left = window_left+(len(tokens)-i)\n",
    "            return tokens[i-window_left+1:i]+tokens[i:i+window_right]\n",
    "        else:\n",
    "            return []\n",
    "  \n",
    "    def predict(self, window=2):\n",
    "        \n",
    "        '''\n",
    "            predict by getting the left words;getting rid of extra dimentions;\n",
    "            converting words to ids and then turning into probabilities of the given model;\n",
    "            picking the maximum predicted choice\n",
    "        :param: window\n",
    "        :return: prediction\n",
    "        '''\n",
    "        \n",
    "        context = self.get_window_context(self.sentence, window, window)\n",
    "        context = torch.tensor([word_to_ix[w] for w in context])\n",
    "        _, log_probs = model(torch.unsqueeze(context, dim=0), target=None)\n",
    "        log_probs = torch.squeeze(log_probs)\n",
    "        choice_ids = {index:word_to_ix[word] for index,word in self.word_choices.items() if word in word_to_ix.keys()}\n",
    "        choice_probs = {index:float(log_probs[id]) for index, id in choice_ids.items()}\n",
    "        prediction = max(choice_probs, key=choice_probs.get)\n",
    "        return prediction\n",
    "\n",
    "    def predict_and_score(self):\n",
    "        \n",
    "        '''\n",
    "            comparing the prediction with the correct answer\n",
    "        ;return:1/0\n",
    "        '''\n",
    "        \n",
    "        prediction=self.predict()\n",
    "        if prediction == self.answer:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mrscc_reader:\n",
    "    def __init__(self, model, qs=questions, ans=answers):\n",
    "        \n",
    "        '''\n",
    "            This is the constructor method\n",
    "        :param: model, qs, ans\n",
    "        '''   \n",
    "        \n",
    "        self.qs=qs\n",
    "        self.ans=ans\n",
    "        self.model = model\n",
    "        self.read_files()\n",
    "\n",
    "    def read_files(self):\n",
    "        \n",
    "        '''\n",
    "            Reading the files; adding answers to the question, to check the prediction\n",
    "        '''\n",
    "\n",
    "        self.questions=[question(questions.iloc[i], self.model) for i in range(len(questions))]\n",
    "\n",
    "        for i,q in enumerate(self.questions):\n",
    "            q.add_answer(answers.iloc[i])\n",
    "\n",
    "    def get_field(self,field):\n",
    "        '''\n",
    "            retriving the questions field\n",
    "        '''\n",
    "        return [q.get_field(field) for q in self.questions] \n",
    "\n",
    "    def predict(self):\n",
    "        return [q.predict() for q in self.questions]\n",
    "\n",
    "    def predict_and_score(self):\n",
    "        scores=[q.predict_and_score() for q in self.questions]\n",
    "        return sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC = mrscc_reader(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCC.predict_and_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.squeeze(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
